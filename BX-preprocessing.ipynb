{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as spsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv('BX-Books.csv', sep='\\\";\\\"', encoding = 'cp1252')\n",
    "ratings = pd.read_csv('BX-Book-Ratings.csv', sep=';', encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID         ISBN  Book-Rating\n",
       "0         276725   034545104X            0\n",
       "1         276726   0155061224            5\n",
       "2         276727   0446520802            0\n",
       "3         276729   052165615X            3\n",
       "4         276729   0521795028            6\n",
       "...          ...          ...          ...\n",
       "1149775   276704   1563526298            9\n",
       "1149776   276706   0679447156            0\n",
       "1149777   276709   0515107662           10\n",
       "1149778   276721   0590442449           10\n",
       "1149779   276723  05162443314            8\n",
       "\n",
       "[1149780 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_content = pd.read_csv('compiled_books_content.txt.gz', sep='\\t', encoding = 'cp1252', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0877853134</td>\n",
       "      <td>June 1, 2004</td>\n",
       "      <td>The Arrivals Naomi Gladish Smith</td>\n",
       "      <td>Flight 785 is bound for London and Brussels, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3426620685</td>\n",
       "      <td>March 1, 2002</td>\n",
       "      <td>Süden und der Straßenbahntrinker. Friedrich An...</td>\n",
       "      <td>Tabor S&amp;#xFC;den hat Urlaub, baut &amp;#xDC;berstu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006513905</td>\n",
       "      <td>December 15, 1999</td>\n",
       "      <td>Dice Man  Luke Rhinehart</td>\n",
       "      <td>The cult classic that can still change your li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0062506838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Enneagram Understanding Yourself and the O...</td>\n",
       "      <td>It would be impossible for most of us to spend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0099435446</td>\n",
       "      <td>July 3, 2003</td>\n",
       "      <td>Babes in the Wood  Ruth Rendell</td>\n",
       "      <td>A woman phoned to say she and her husband went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36523</th>\n",
       "      <td>0312195516</td>\n",
       "      <td>September 15, 1998</td>\n",
       "      <td>The Red Tent Anita Diamant</td>\n",
       "      <td>Her name is Dinah. In the Bible, her life is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36524</th>\n",
       "      <td>0060928336</td>\n",
       "      <td>May 7, 1997</td>\n",
       "      <td>Divine Secrets of the Ya-Ya Sisterhood A Novel...</td>\n",
       "      <td>When Siddalee Walker, oldest daughter of Vivi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36525</th>\n",
       "      <td>0385504209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Da Vinci Code Dan Brown</td>\n",
       "      <td>While in Paris on business, Harvard symbologis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36526</th>\n",
       "      <td>0316666343</td>\n",
       "      <td>June 1, 2002</td>\n",
       "      <td>The Lovely Bones  Alice Sebold</td>\n",
       "      <td>This deluxe trade paperback edition of Alice S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36527</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>September 2004</td>\n",
       "      <td>Wild Animus A Novel Rich Shapero</td>\n",
       "      <td>After graduating from college, Sam Altman find...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36528 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                    1  \\\n",
       "0      0877853134         June 1, 2004   \n",
       "1      3426620685        March 1, 2002   \n",
       "2      0006513905    December 15, 1999   \n",
       "3      0062506838                  NaN   \n",
       "4      0099435446         July 3, 2003   \n",
       "...           ...                  ...   \n",
       "36523  0312195516   September 15, 1998   \n",
       "36524  0060928336          May 7, 1997   \n",
       "36525  0385504209                  NaN   \n",
       "36526  0316666343         June 1, 2002   \n",
       "36527  0971880107       September 2004   \n",
       "\n",
       "                                                       2  \\\n",
       "0                    The Arrivals Naomi Gladish Smith      \n",
       "1      Süden und der Straßenbahntrinker. Friedrich An...   \n",
       "2                              Dice Man  Luke Rhinehart    \n",
       "3      The Enneagram Understanding Yourself and the O...   \n",
       "4                       Babes in the Wood  Ruth Rendell    \n",
       "...                                                  ...   \n",
       "36523                      The Red Tent Anita Diamant      \n",
       "36524  Divine Secrets of the Ya-Ya Sisterhood A Novel...   \n",
       "36525                     The Da Vinci Code Dan Brown      \n",
       "36526                    The Lovely Bones  Alice Sebold    \n",
       "36527                Wild Animus A Novel Rich Shapero      \n",
       "\n",
       "                                                       3  \n",
       "0      Flight 785 is bound for London and Brussels, b...  \n",
       "1      Tabor S&#xFC;den hat Urlaub, baut &#xDC;berstu...  \n",
       "2      The cult classic that can still change your li...  \n",
       "3      It would be impossible for most of us to spend...  \n",
       "4      A woman phoned to say she and her husband went...  \n",
       "...                                                  ...  \n",
       "36523  Her name is Dinah. In the Bible, her life is o...  \n",
       "36524  When Siddalee Walker, oldest daughter of Vivi ...  \n",
       "36525  While in Paris on business, Harvard symbologis...  \n",
       "36526  This deluxe trade paperback edition of Alice S...  \n",
       "36527  After graduating from college, Sam Altman find...  \n",
       "\n",
       "[36528 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to collect all books and assign them with sequence numbers.\n",
    "\n",
    "We filter books. We have to make sure a book has metadata and content. We only collect English books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#books: 34446\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# the books with metadata.\n",
    "isbn_set = set()\n",
    "for i in range(len(books['\\\"ISBN'])):\n",
    "    isbn = books['\\\"ISBN'][i][1:]\n",
    "    isbn_set.add(isbn)\n",
    "\n",
    "# the books with more detailed content information.\n",
    "book_map = {}\n",
    "num_books = 0\n",
    "for book, abstract in zip(book_content[0], book_content[3]):\n",
    "    if book in book_map or book not in isbn_set:\n",
    "        continue\n",
    "    try:\n",
    "        if detect(abstract) == 'en':\n",
    "            book_map[book] = num_books\n",
    "            num_books += 1\n",
    "    except:\n",
    "        continue\n",
    "assert len(book_map) == num_books\n",
    "print('#books:', num_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271374</th>\n",
       "      <td>\"0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271375</th>\n",
       "      <td>\"0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271376</th>\n",
       "      <td>\"006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271377</th>\n",
       "      <td>\"0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271378</th>\n",
       "      <td>\"0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271379 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              \"ISBN                                         Book-Title  \\\n",
       "0       \"0195153448                                Classical Mythology   \n",
       "1       \"0002005018                                       Clara Callan   \n",
       "2       \"0060973129                               Decision in Normandy   \n",
       "3       \"0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       \"0393045218                             The Mummies of Urumchi   \n",
       "...             ...                                                ...   \n",
       "271374  \"0440400988                         There's a Bat in Bunk Five   \n",
       "271375  \"0525447644                            From One to One Hundred   \n",
       "271376  \"006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271377  \"0192126040                        Republic (World's Classics)   \n",
       "271378  \"0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                 Book-Author  Year-Of-Publication  \\\n",
       "0         Mark P. O. Morford                 2002   \n",
       "1       Richard Bruce Wright                 2001   \n",
       "2               Carlo D'Este                 1991   \n",
       "3           Gina Bari Kolata                 1999   \n",
       "4            E. J. W. Barber                 1999   \n",
       "...                      ...                  ...   \n",
       "271374        Paula Danziger                 1988   \n",
       "271375            Teri Sloat                 1991   \n",
       "271376      Christine Wicker                 2004   \n",
       "271377                 Plato                 1996   \n",
       "271378   Christopher  Biffle                 2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp; Company   \n",
       "...                                                  ...   \n",
       "271374                   Random House Childrens Pub (Mm)   \n",
       "271375                                      Dutton Books   \n",
       "271376                                HarperSanFrancisco   \n",
       "271377                           Oxford University Press   \n",
       "271378  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271374  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271375  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271376  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271377  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271378  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271374  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271375  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271376  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271377  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271378  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                             Image-URL-L\"  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271374  http://images.amazon.com/images/P/0440400988.0...  \n",
       "271375  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271376  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271377  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271378  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[271379 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all of the metadata of the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34446\n"
     ]
    }
   ],
   "source": [
    "book_titles = {}\n",
    "book_authors = {}\n",
    "book_years = np.zeros(shape=(num_books))\n",
    "book_publishers = {}\n",
    "book_abstracts = {}\n",
    "\n",
    "for i in range(len(books['\\\"ISBN'])):\n",
    "    isbn = books['\\\"ISBN'][i][1:]\n",
    "    title = books['Book-Title'][i]\n",
    "    author = books['Book-Author'][i]\n",
    "    year = books['Year-Of-Publication'][i]\n",
    "    publisher = books['Publisher'][i]\n",
    "    if isbn not in book_map:\n",
    "        continue\n",
    "    book_idx = book_map[isbn]\n",
    "    book_titles[book_idx] = title\n",
    "    book_authors[book_idx] = author\n",
    "    book_years[book_idx] = year\n",
    "    book_publishers[book_idx] = publisher\n",
    "print(len(book_titles))\n",
    "    \n",
    "for isbn, title, abstract in zip(book_content[0], book_content[2], book_content[3]):\n",
    "    if isbn in book_map:\n",
    "        idx = book_map[isbn]\n",
    "        book_abstracts[idx] = abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the ratings on the books with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623439\n"
     ]
    }
   ],
   "source": [
    "filter_ratings = []\n",
    "for user, isbn, rate in zip(ratings['User-ID'], ratings['ISBN'], ratings['Book-Rating']):\n",
    "    if isbn in book_map:\n",
    "        filter_ratings.append((user, isbn, rate))\n",
    "        \n",
    "print(len(filter_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all users that read books with metadata. The users are assigned with sequence numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66485\n",
      "#users: 66485\n"
     ]
    }
   ],
   "source": [
    "user_map = {}\n",
    "num_users = 0\n",
    "for user, _, _ in filter_ratings:\n",
    "    if user not in user_map:\n",
    "        user_map[user] = num_users\n",
    "        num_users += 1\n",
    "assert len(user_map) == num_users\n",
    "print('#users:', num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a sparse matrix for the user-book interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66485, 34446)\n"
     ]
    }
   ],
   "source": [
    "user_arr = np.array([user_map[user] for user, _, _ in filter_ratings], dtype=np.int64)\n",
    "book_arr = np.array([book_map[isbn] for _, isbn, _ in filter_ratings], dtype=np.int64)\n",
    "rate_arr = np.array([rate for _, _, rate in filter_ratings], dtype=np.int64)\n",
    "\n",
    "user_book_spm = spsp.coo_matrix((np.ones((len(user_arr))), (user_arr, book_arr)))\n",
    "user_book_ratings = spsp.coo_matrix((rate_arr, (user_arr, book_arr)))\n",
    "print(user_book_spm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the users read less two books. In this case, we cannot use them in testing or validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "user_deg = user_book_spm.dot(np.ones((num_books)))\n",
    "print(np.sum(user_deg <= 2))\n",
    "book_deg = user_book_spm.transpose().dot(np.ones((num_users)))\n",
    "print(np.sum(book_deg <= 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new mapping between original user id and new id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#users: 21890\n"
     ]
    }
   ],
   "source": [
    "user_map1 = {}\n",
    "num_users = 0\n",
    "for user, _, _ in filter_ratings:\n",
    "    orig_idx = user_map[user]\n",
    "    if user not in user_map1 and user_deg[orig_idx] > 2:\n",
    "        user_map1[user] = num_users\n",
    "        num_users += 1\n",
    "assert len(user_map1) == num_users\n",
    "print('#users:', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21890, 34446)\n"
     ]
    }
   ],
   "source": [
    "user_book_spm = user_book_spm.tocsr()[user_deg > 2]\n",
    "user_book_ratings = user_book_ratings.tocsr()[user_deg > 2]\n",
    "print(user_book_spm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#attributes: 11103\n",
      "196\n",
      "#attributes: 1653\n",
      "1238\n",
      "#years: 80\n",
      "max #books a year: 2834\n"
     ]
    }
   ],
   "source": [
    "def counts(book_attributes):\n",
    "    popularity = {}\n",
    "    for _, author in book_attributes.items():\n",
    "        if author in popularity:\n",
    "            popularity[author] += 1\n",
    "        else:\n",
    "            popularity[author] = 1\n",
    "    print('#attributes:', len(popularity))\n",
    "    print(np.max([p for _, p in popularity.items()]))\n",
    "    \n",
    "counts(book_authors)\n",
    "counts(book_publishers)\n",
    "uniq_years, year_cnts = np.unique(book_years, return_counts=True)\n",
    "print('#years:', len(uniq_years))\n",
    "print('max #books a year:', np.max(year_cnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn, Block\n",
    "import gluonnlp as nlp\n",
    "import time\n",
    "import random\n",
    "from gluonnlp.data import BERTTokenizer\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "mx.random.seed(123)\n",
    "\n",
    "dropout_prob = 0.1\n",
    "ctx = mx.cpu(0)\n",
    "\n",
    "bert_model, bert_vocab = nlp.model.get_model(name='bert_12_768_12',\n",
    "                                             dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                             pretrained=True,\n",
    "                                             ctx=ctx,\n",
    "                                             use_pooler=True,\n",
    "                                             use_decoder=False,\n",
    "                                             use_classifier=False,\n",
    "                                             dropout=dropout_prob,\n",
    "                                             embed_dropout=dropout_prob)\n",
    "tokenizer = BERTTokenizer(bert_vocab, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abstract_emb = mx.nd.zeros(shape=(num_books, 768))\n",
    "for i in range(num_books):\n",
    "    token_ids = mx.nd.expand_dims(mx.nd.array(bert_vocab[tokenizer(book_abstracts[i])], dtype=np.int32), axis=0)\n",
    "    token_types = mx.nd.ones_like(token_ids)\n",
    "    _, sent_embedding = bert_model(token_ids, token_types)\n",
    "    abstract_emb[i] = sent_embedding.transpose().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb = mx.nd.zeros(shape=(num_books, 768))\n",
    "for i in range(num_books):\n",
    "    token_ids = mx.nd.expand_dims(mx.nd.array(bert_vocab[tokenizer(book_titles[i])], dtype=np.int32), axis=0)\n",
    "    token_types = mx.nd.ones_like(token_ids)\n",
    "    _, sent_embedding = bert_model(token_ids, token_types)\n",
    "    title_emb[i] = sent_embedding.transpose().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34446, 768)\n",
      "(34446, 768)\n"
     ]
    }
   ],
   "source": [
    "print(abstract_emb.shape)\n",
    "print(title_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training size: 526851\n",
      "valid set: 21890\n",
      "test set: 21890\n"
     ]
    }
   ],
   "source": [
    "def pick_test(user_book_spm):\n",
    "    users = user_book_spm.row\n",
    "    items = user_book_spm.col\n",
    "    picks = np.zeros(shape=(len(users)))\n",
    "    user_book_spm = user_book_spm.tocsr()\n",
    "    indptr = user_book_spm.indptr\n",
    "    valid_set = np.zeros(shape=(num_users))\n",
    "    test_set = np.zeros(shape=(num_users))\n",
    "    for i in range(user_book_spm.shape[0]):\n",
    "        start_idx = indptr[i]\n",
    "        end_idx = indptr[i+1]\n",
    "        idx = np.random.choice(np.arange(start_idx, end_idx), 2, replace=False)\n",
    "        valid_set[i] = items[idx[0]]\n",
    "        picks[idx[0]] = 1\n",
    "        test_set[i] = items[idx[1]]\n",
    "        picks[idx[1]] = 1\n",
    "    users = users[picks == 0]\n",
    "    items = items[picks == 0]\n",
    "    return spsp.coo_matrix((np.ones((len(users),)), (users, items))), valid_set, test_set\n",
    "\n",
    "orig_user_book_spm = user_book_spm.tocsr()\n",
    "user_book_spm, valid_set, test_set = pick_test(user_book_spm.tocoo())\n",
    "print('#training size:', user_book_spm.nnz)\n",
    "users_valid = np.arange(num_users)\n",
    "items_valid = valid_set\n",
    "users_test = np.arange(num_users)\n",
    "items_test = test_set\n",
    "valid_size = len(users_valid)\n",
    "test_size = len(users_test)\n",
    "print('valid set:', valid_size)\n",
    "print('test set:', test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(user_book_spm, open('bx_train.pkl', 'wb'))\n",
    "pickle.dump(abstract_emb, open('bx_book_abstract.pkl', 'wb'))\n",
    "pickle.dump(title_emb, open('bx_book_title.pkl', 'wb'))\n",
    "pickle.dump(user_map1, open('bx_user_map.pkl', 'wb'))\n",
    "pickle.dump(book_map, open('bx_book_map.pkl', 'wb'))\n",
    "pickle.dump((valid_set, test_set), open('bx_eval.pkl', 'wb'))\n",
    "pickle.dump((neg_valid, neg_test), open('bx_neg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
